{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Large Language Model Challenge: LLM StoryBot\n",
        "Data Science Sprint 15 Challenge\n",
        "Challenge Objectives üßæ\n",
        "You should be able to...\n",
        "\n",
        "Implement an LLM (either local or API based)\n",
        "Customize the behavior of an LLM\n",
        "Use a custom LLM in your terminal\n",
        "You may use any Python libraries that can be installed via pip, including the Python standard library. Please do not use any websites like ChatGPT to write your stories. You are welcome to use them to help write the code for your custom model, though! Pro Tip: ask them to act as teachers to help you learn rather than just getting them to write the code for you."
      ],
      "metadata": {
        "id": "8F6ku-pPTK3J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1 - Choose an LLM Model üîç\n",
        "The easy choice here is OpenAi's API version of GPT, but it requires a paid account. If you want a higher-level challenge, choose an open-source model that runs locally. Although GPT is easier to set up and performs better than open-source models, you will learn way more if you implement a local open-source model."
      ],
      "metadata": {
        "id": "PO9otO8pTNEG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2 - Implement an LLM Model as a Brilliant Storyteller Bot ü§ñ\n",
        "Design an LLM that acts like a brilliant storyteller by having it generate a story based on user input. The stories should be about 1000 words in length or longer.\n",
        "\n",
        "Be mindful of the context window of the model you choose. The system_prompt, user_prompt, and output combined need to fit inside one context window. See the documentation for the model you're using for more details. Pro Tip: choose a model with good documentation! üòè"
      ],
      "metadata": {
        "id": "QAB6WxRATQni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "class StoryBot:\n",
        "    def __init__(self):\n",
        "\n",
        "        #self.tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "        self.tokenizer = tokenizer\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "        #self.model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "    def __call__(self, user_prompt: str, max_length: int = 1000) -> str:\n",
        "        input_ids = self.tokenizer.encode(user_prompt, return_tensors=\"pt\")\n",
        "        output = self.model.generate(input_ids, max_length=max_length, num_return_sequences=1)\n",
        "        generated_text = self.tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "        return generated_text"
      ],
      "metadata": {
        "id": "KT22X3aqTe2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 3 - StoryBot Testing üß™\n",
        "Have your bot write a few stories and evaluate them. Can alterations be made to the model's parameters to improve the results?"
      ],
      "metadata": {
        "id": "lO4TcgELTkoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "model.config.pad_token_id = model.config.eos_token_id"
      ],
      "metadata": {
        "id": "RrmwRLN1TlVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"A short film about a pilot who \"\n",
        "story_bot = StoryBot()\n",
        "story_bot(user_prompt)"
      ],
      "metadata": {
        "id": "_Rez0bFDTufm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 4 - Story Submission üìú\n",
        "Have your bot generate at least three stories and choose your favorite to upload for evaluation. The story should be 1000 words or more and be purely AI-generated. Please do not edit the story in any way. To submit your Sprint Challenge, upload your story.txt file by itself.\n",
        "\n",
        "Stretch Goals (Optional) üèÑ\n",
        "Have the call method of the bot output a story as a txt file rather than printing to the terminal, so you don't need to copy/paste for submission.\n",
        "Give your bot a distinct personality on top of its ability to write captivating stories.\n",
        "Implement a memory module for your bot. A memory module would give you the ability to have it do multiple revisions of the same story based on your input.\n",
        "Implement an API (Flask or FastAPI) to interact with your bot.\n"
      ],
      "metadata": {
        "id": "eoiDJqggT14-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congratulations! ü•≥\n",
        "Thank you for your hard work, and congratulations!!! You've learned a lot, and you should proudly call yourself a Data Scientist."
      ],
      "metadata": {
        "id": "h798_mYhT7ic"
      }
    }
  ]
}